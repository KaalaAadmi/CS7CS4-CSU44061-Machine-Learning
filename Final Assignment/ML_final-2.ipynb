{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W406Hb35_FBz",
        "outputId": "e00e0f7b-a53f-4427-f1e6-b80e2ceeda6d"
      },
      "outputs": [],
      "source": [
        "# !pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-KJyVGY5suT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns; sns.set()\n",
        "import csv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "REVIEWS DATA CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqOMHcq99WD8",
        "outputId": "f1b3356f-9d9e-4bf4-a61f-20ff9411359a"
      },
      "outputs": [],
      "source": [
        "df_reviews = pd.read_csv('reviews.csv')\n",
        "\n",
        "print(df_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwYTr4b9eqy",
        "outputId": "af8e64f5-4ad6-496b-c634-a2ab8e3da3de"
      },
      "outputs": [],
      "source": [
        "clean_reviews = df_reviews.drop([\"date\", \"reviewer_name\"], axis=1)\n",
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVRcNgCO-XJy",
        "outputId": "7512ee71-6d21-4b60-e3f7-4a160aa94334"
      },
      "outputs": [],
      "source": [
        "clean_reviews['comments'] = clean_reviews['comments'].str.lower()\n",
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIwFp2mC_No2"
      },
      "outputs": [],
      "source": [
        "def det(x):\n",
        "    try:\n",
        "        return detect(x)\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "clean_reviews['Lang'] = clean_reviews['comments'].apply(det)\n",
        "clean_reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NEZyeF6CyIX"
      },
      "outputs": [],
      "source": [
        "clean_reviews = clean_reviews[clean_reviews[\"Lang\"] == \"en\"].drop([\"Lang\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_reviews.to_csv('clean_review.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_reviews = pd.read_csv('clean_review.csv')\n",
        "# clean_reviews = clean_reviews[['listing_id', 'comments']]\n",
        "clean_reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.patches as mpatches\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c = clean_reviews.loc[:,'comments']\n",
        "print(c.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sid_obj = SentimentIntensityAnalyzer()\n",
        "count = 0\n",
        "sent = []\n",
        "for a in c:\n",
        "  n = sid_obj.polarity_scores(a)\n",
        "  count = count+1\n",
        "  # print(count)\n",
        "  sent.append(n['compound'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_reviews['Sentiment']= sent\n",
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_reviews.to_csv('clean_review.csv',index = False)\n",
        "clean_reviews = pd.read_csv('clean_review.csv')\n",
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pd.set_option('max_rows', 99999)\n",
        "# pd.set_option('max_colwidth',9999999)\n",
        "# pd.describe_option('max_colwidth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_reviews = clean_reviews.sort_values('listing_id')\n",
        "print(clean_reviews.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l = clean_reviews.loc[:,'listing_id']\n",
        "s = clean_reviews.loc[:,'Sentiment']\n",
        "\n",
        "l.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sen = []\n",
        "new_id = [] \n",
        "idx = 0\n",
        "i = 0\n",
        "\n",
        "while(i<l.size):\n",
        "    cnt = 0\n",
        "    sum = 0\n",
        "    id = l[i]\n",
        "    new_id.append(id)\n",
        "\n",
        "    # while( i<l.size):\n",
        "        # print(\"HERE\")\n",
        "    while( i<l.size and l[i]==id ):\n",
        "        cnt = cnt + 1\n",
        "        sum = sum + s[i]\n",
        "        i = i + 1\n",
        "        print(str(id) + \" Count = \"+ str(cnt))\n",
        "\n",
        "    # print(\"HERE: \"+ str(l[i])+ \" \"+str(id))\n",
        "    \n",
        "    new_sen.append(round((sum/cnt),5))\n",
        "    print(\"ID:\" + str(new_id[idx]) + \" SEN:\" + str(new_sen[idx]) + \" SUM:\" + str(sum))\n",
        "    print(\"------------------\")\n",
        "    idx = idx + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l = clean_reviews.loc[:,'listing_id']\n",
        "c = clean_reviews.loc[:,'comments']\n",
        "\n",
        "new_comm = []\n",
        "temp_id = [] \n",
        "idx = 0\n",
        "i = 0\n",
        "\n",
        "while(i<l.size):\n",
        "    cnt = 0\n",
        "    all_comm = \" \"\n",
        "    id = l[i]\n",
        "    temp_id.append(id)\n",
        "\n",
        "    # while( i<l.size):\n",
        "        # print(\"HERE\")\n",
        "    while( i<l.size and l[i]==id ):\n",
        "        cnt = cnt + 1\n",
        "        all_comm = all_comm + c[i]\n",
        "        i = i + 1\n",
        "        print(str(id) + \" Count = \"+ str(cnt))\n",
        "\n",
        "    # print(\"HERE: \"+ str(l[i])+ \" \"+str(id))\n",
        "    \n",
        "    new_comm.append(all_comm)\n",
        "    print(\"ID:\" + str(temp_id[idx]) + \" LENGTH:\" + str(len(all_comm)))\n",
        "    print(\"------------------\")\n",
        "    idx = idx + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(new_sen),len(new_id),len(new_comm))\n",
        "# new_comm[0]\n",
        "\n",
        "final_reviews = pd.DataFrame({'id':new_id, 'comments':new_comm, 'sentiment': new_sen})\n",
        "final_reviews.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_reviews.to_csv('final_reviews.csv',index = False)\n",
        "final_reviews = pd.read_csv('final_reviews.csv')\n",
        "final_reviews.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LISTING DATA CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing = pd.read_csv('listings.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing=df_listing.drop([\"listing_url\", \"scrape_id\", \"last_scraped\", \"source\", \"name\", \"picture_url\", \"host_id\", \"host_name\", \"host_url\",\n",
        "\"host_thumbnail_url\", \"host_picture_url\", \"neighbourhood_group_cleansed\", \"bathrooms\", \"license\", \"host_location\", \"host_since\",\"first_review\",\"last_review\"], axis=1)\n",
        "\n",
        "df_listing = df_listing.drop(['neighbourhood', 'neighbourhood_cleansed','calendar_updated','calendar_last_scraped'],axis=1)\n",
        "\n",
        "df_listing = df_listing.drop(['minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm'],axis=1)\n",
        "\n",
        "df_listing = df_listing.drop(['neighborhood_overview', 'host_about', 'host_response_time', 'host_acceptance_rate','host_neighbourhood'],axis=1) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing.columns.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df_listing.loc[:,['id','latitude','longitude']]\n",
        "df_listing = df_listing.drop(['latitude', 'longitude'],axis=1)\n",
        "\n",
        "\n",
        "X.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# K_clusters = range(1,10)\n",
        "# kmeans = [KMeans(n_clusters=i) for i in K_clusters]\n",
        "# Y_axis = X[['latitude']]\n",
        "# X_axis = X[['longitude']]\n",
        "# score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]# Visualize\n",
        "# plt.plot(K_clusters, score)\n",
        "# plt.xlabel('Number of Clusters')\n",
        "# plt.ylabel('Score')\n",
        "# plt.title('Elbow Curve')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = 7, init ='k-means++')\n",
        "kmeans.fit(X[X.columns[1:3]]) # Compute k-means clustering.\n",
        "X['cluster_label'] = kmeans.fit_predict(X[X.columns[1:3]])\n",
        "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
        "labels = kmeans.predict(X[X.columns[1:3]]) # Labels of each point\n",
        "X.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')\n",
        "# plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X.drop(['latitude', 'longitude'],axis=1)\n",
        "\n",
        "\n",
        "df_listing = df_listing.merge(X, left_on='id', right_on='id')\n",
        "# df_listing.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing['host_response_rate'] = df_listing['host_response_rate'].str.replace('%', '')\n",
        "df_listing['host_response_rate'] = df_listing['host_response_rate'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.host_response_rate)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_rating)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_accuracy)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_cleanliness)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_checkin)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_communication)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_location)\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10,6))\n",
        "# sns.distplot(df_listing.review_scores_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mean_value_1=round(df_listing['host_response_rate'].mean(),3)\n",
        "\n",
        "# mean_value_2=round(df_listing['review_scores_rating'].mean(),3)\n",
        "\n",
        "# mean_value_3=round(df_listing['review_scores_accuracy'].mean(),3)\n",
        "\n",
        "# mean_value_4=round(df_listing['review_scores_cleanliness'].mean(),3)\n",
        "\n",
        "# mean_value_5=round(df_listing['review_scores_checkin'].mean(),3)\n",
        "\n",
        "# mean_value_6=round(df_listing['review_scores_communication'].mean(),3)\n",
        "\n",
        "# mean_value_7=round(df_listing['review_scores_location'].mean(),3)\n",
        "\n",
        "# mean_value_8=round(df_listing['review_scores_value'].mean(),3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_listing['host_response_rate'].fillna(value=mean_value_1, inplace=True)\n",
        "# df_listing['review_scores_rating'].fillna(value=mean_value_2, inplace=True)\n",
        "# df_listing['review_scores_accuracy'].fillna(value=mean_value_3, inplace=True)\n",
        "# df_listing['review_scores_cleanliness'].fillna(value=mean_value_4, inplace=True)\n",
        "# df_listing['review_scores_checkin'].fillna(value=mean_value_5, inplace=True)\n",
        "# df_listing['review_scores_communication'].fillna(value=mean_value_6, inplace=True)\n",
        "# df_listing['review_scores_location'].fillna(value=mean_value_7, inplace=True)\n",
        "# df_listing['review_scores_value'].fillna(value=mean_value_8, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_temp = df_listing.copy\n",
        "df_temp = df_listing.loc[:,['bedrooms','beds','host_response_rate','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value','reviews_per_month']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linearreg = LinearRegression()\n",
        "imp = IterativeImputer(estimator=linearreg,missing_values=np.nan, max_iter=100, verbose=2, imputation_order='roman',random_state=0)\n",
        "ImputedData=imp.fit_transform(df_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_temp['host_response_rate'].isna().sum()\n",
        "ImputedData = pd.DataFrame(ImputedData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install miceforest\n",
        "# !pip install missingpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "knn = KNNImputer(n_neighbors=2)\n",
        "ImputedData1 = knn.fit_transform(df_temp)\n",
        "ImputedData1 = pd.DataFrame(ImputedData1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = ['bedrooms','beds','host_response_rate','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value','reviews_per_month']\n",
        "i = 0\n",
        "\n",
        "for ele in arr:\n",
        "    mean_value_1 = round(df_temp[ele].mean(),3)\n",
        "    mean_value_2 = round(ImputedData[i].mean(),3)\n",
        "    mean_value_3 = round(ImputedData1[i].mean(),3)\n",
        "    i=i+1\n",
        "\n",
        "    print(mean_value_1,mean_value_2,mean_value_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.distplot(ImputedData[7])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.distplot(ImputedData1[7])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.distplot(df_temp.review_scores_value)\n",
        "\n",
        "# ['host_response_rate','review_scores_rating','review_scores_accuracy','review_scores_cleanliness','review_scores_checkin',\n",
        "# 'review_scores_communication','review_scores_location','review_scores_value']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "\n",
        "for ele in arr:\n",
        "    df_temp[ele] = ImputedData1[i]\n",
        "    i=i+1\n",
        "\n",
        "# df_temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ele in arr:\n",
        "    df_listing[ele] = df_temp[ele]\n",
        "\n",
        "df_listing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df_listing.loc[:,['id','bathrooms_text']]\n",
        "bathrooms_text_map = {'0 shared baths':1,\n",
        "                      '0 baths': 1,\n",
        "                      'Shared half-bath': 2,\n",
        "                      'Half-bath':3,\n",
        "                      'Private half-bath':4,\n",
        "                      '1 shared bath':5,\n",
        "                      '1 bath': 6,\n",
        "                      '1 private bath': 7,\n",
        "                      '1.5 baths': 9,\n",
        "                      '1.5 shared baths': 8,\n",
        "                      '2 shared baths':10,\n",
        "                      '2 baths':11,\n",
        "                      '2.5 shared baths': 12,\n",
        "                      '2.5 baths': 13,\n",
        "                      '3 shared baths': 14,\n",
        "                      '3 baths': 15,\n",
        "                      '3.5 shared baths': 16,\n",
        "                      '3.5 baths': 17,\n",
        "                      '4 shared baths': 18,\n",
        "                      '4 baths': 19,\n",
        "                      '4.5 baths': 20,\n",
        "                      '5 baths': 21,\n",
        "                      '5.5 baths': 22,\n",
        "                      '6 shared baths': 23,\n",
        "                      '6 baths': 24,\n",
        "                      '6.5 baths': 25,\n",
        "                      '7 baths': 26,\n",
        "                      '7.5 baths': 27,\n",
        "                      '8 baths': 28,\n",
        "                      '8.5 baths': 29,\n",
        "                      '9.5 baths': 30}\n",
        "\n",
        "X['bathroom_map'] = X.bathrooms_text.map(bathrooms_text_map)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing = df_listing.drop(['bathrooms_text'], axis=1).merge(X, left_on='id', right_on='id')\n",
        "df_listing['bathroom_map'] = df_listing['bathroom_map'].fillna(6)\n",
        "df_listing = df_listing.drop(['bathrooms_text'], axis=1)\n",
        "df_listing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listing.to_csv('final_listing.csv',index = False)\n",
        "final_listing = pd.read_csv('final_listing.csv')\n",
        "final_listing.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listings_final = pd.read_csv('final_listing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert text to lowercase.\n",
        "import re\n",
        "\n",
        "def convert_empty_to_nan( df, column_name ) :\n",
        "    df[ column_name ] = df[ column_name ].str.lower()\n",
        "    df[ column_name ] = df[ column_name ].fillna(\"NA\") \n",
        "    df[ column_name ] = df[ column_name ].str.replace(\"[^a-zA-Z0-9]+\", ' ', regex=True)\n",
        "    # re.sub(r\"[^a-zA-Z0-9]+\", ' ', k)\n",
        "    df[ column_name ] = df[ column_name ].str.replace('\\d+', '', regex=True)\n",
        "    #.replace(r'^\\s*$', \"No description\", regex=True)\n",
        "\n",
        "convert_empty_to_nan( df_listings_final, 'description' )\n",
        "\n",
        "# df_listings_final['description'].head()\n",
        "\n",
        "# df_listings_final.to_csv( '../data/listingsDesc.csv', index=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing stop words (un-necessary words) - using nltk's pre-defined stop words\n",
        "STOP_WORDS = set( stopwords.words('english') )\n",
        "STOP_WORDS.add(\"br\")\n",
        "# print('Stop word list:')\n",
        "# print('----------------')\n",
        "# print(STOP_WORDS)\n",
        "\n",
        "def remove_stop_words(content):\n",
        "   return \" \".join([text for text in str(content).split() if text not in STOP_WORDS])\n",
        "\n",
        "df_listings_final['description'] = df_listings_final['description'].apply(lambda content: remove_stop_words(content=content))\n",
        "\n",
        "# df_listings_final['description'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def stemming(x):\n",
        "    words = word_tokenize(x)\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        words[i] = ps.stem(words[i])\n",
        "\n",
        "    return (' '.join(map(str, words)))\n",
        "\n",
        "df_listings_final['description'] = df_listings_final.apply(lambda row : stemming(row['description']), axis = 1)\n",
        "df_listings_final.description.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "# result = tfidf.fit_transform(string)\n",
        "\n",
        "temp = df_listings_final\n",
        "temp_f = temp['description']\n",
        "# print(temp['description'])\n",
        "x = tfidf.fit_transform(temp['description'])\n",
        "\n",
        "df1 = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
        "# print(df1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "term = []\n",
        "score = []\n",
        "for ele1, ele2 in zip(tfidf.get_feature_names(), tfidf.idf_):\n",
        "    term.append(ele1)\n",
        "    score.append(ele2)\n",
        "\n",
        "term_scores = pd.DataFrame({'term':term, 'score':score})\n",
        "term_scores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "term_scores = term_scores.sort_values(by=['score'],ascending=False)\n",
        "print(term_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listings_final = pd.read_csv('final_listing.csv')\n",
        "\n",
        "df_listings_final = df_listings_final.drop(['description'],axis=1)\n",
        "\n",
        "# df_listings_final = df_listings_final.drop(['room_type'],axis=1)\n",
        "# df_listings_final = df_listings_final.drop(['property_type'],axis=1)\n",
        "# df_listings_final = df_listings_final.drop(['host_verifications'],axis=1)\n",
        "# df_listings_final = df_listings_final.drop(['amenities'],axis=1)\n",
        "\n",
        "print(df_listings_final.shape)\n",
        "\n",
        "final_reviews = pd.read_csv('final_reviews.csv')\n",
        "final_reviews = final_reviews.drop(['comments'],axis=1)\n",
        "print(final_reviews.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listings_final['price'] = df_listings_final['price'].str.replace('$', '')\n",
        "df_listings_final['price'] = df_listings_final['price'].str.replace(',', '')\n",
        "df_listings_final['price'] = df_listings_final['price'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_listings_final['host_is_superhost'] = df_listings_final['host_is_superhost'].map({'t': 1, 'f': 0})\n",
        "df_listings_final['host_has_profile_pic'] = df_listings_final['host_has_profile_pic'].map({'t': 1, 'f': 0})\n",
        "df_listings_final['host_identity_verified'] = df_listings_final['host_identity_verified'].map({'t': 1, 'f': 0})\n",
        "df_listings_final['has_availability'] = df_listings_final['has_availability'].map({'t': 1, 'f': 0})\n",
        "df_listings_final['instant_bookable'] = df_listings_final['instant_bookable'].map({'t': 1, 'f': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df = pd.merge(df_listings_final,final_reviews,left_on='id',right_on='id')\n",
        "\n",
        "# final_df = final_df.drop(['id'],axis=1)\n",
        "\n",
        "print(final_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn import preprocessing\n",
        "\n",
        "# x = final_df.values #returns a numpy array\n",
        "# min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# x_scaled = min_max_scaler.fit_transform(x)\n",
        "# df = pd.DataFrame(x_scaled)\n",
        "\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_Number(content):\n",
        "   return len(content.split(','))\n",
        "\n",
        "def punctuation_processing(content):\n",
        "    return str(content).translate(str.maketrans('', '', '!\"#$%&\\'()*+-./:;<=>?@[\\]^_`{|}~\\\\'))\n",
        "\n",
        "\n",
        "X=df_listings_final.loc[:,['id','host_verifications']]\n",
        "X['host_verifications'] = X['host_verifications'].apply(lambda content: punctuation_processing(content=content))\n",
        "X['host_verifications_count'] = X['host_verifications'].apply(lambda content: replace_Number(content=content))\n",
        "X = X.drop(['host_verifications'], axis=1)\n",
        "\n",
        "final_df = final_df.merge(X, left_on='id', right_on='id')\n",
        "final_df = final_df.drop(['host_verifications'], axis=1)\n",
        "\n",
        "final_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df_listings_final.loc[:,['id','amenities']]\n",
        "X['amenities'] = X['amenities'].apply(lambda content: punctuation_processing(content=content))\n",
        "X['amenities_count'] = X['amenities'].apply(lambda content: replace_Number(content=content))\n",
        "X = X.drop(['amenities'], axis=1)\n",
        "\n",
        "final_df = final_df.merge(X, left_on='id', right_on='id')\n",
        "final_df = final_df.drop(['amenities'], axis=1)\n",
        "\n",
        "final_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df['room_type'] = final_df['room_type'].map({'Shared room': 1, 'Hotel room': 2, 'Private room': 3, 'Entire home/apt': 4})\n",
        "final_df = final_df.drop(['property_type'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "#apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=f_regression, k=10)\n",
        "\n",
        "X=final_df\n",
        "X=X.drop('review_scores_location',axis=1)\n",
        "y = pd.DataFrame(final_df['review_scores_location'])\n",
        "\n",
        "# X = final_df.iloc[:,0:19]  #independent columns\n",
        "# y = final_df.iloc[:,20]\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(50,'Score'))  #print 10 best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# data = final_df\n",
        "# X = data.iloc[:,0:19]  #independent columns\n",
        "# y = data.iloc[:,20]    #target column i.e price range\n",
        "# from sklearn.ensemble import ExtraTreesClassifier\n",
        "# import matplotlib.pyplot as plt\n",
        "# model = ExtraTreesClassifier()\n",
        "# model.fit(X,y)\n",
        "# print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "# #plot graph of feature importances for better visualization\n",
        "# feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "# feat_importances.nlargest(10).plot(kind='barh')\n",
        "# plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'host_response_time', 'host_acceptance_rate' fill and try\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aba257262fddbabb4bdbb672c296781410c54125b9dd9ae65f0141fbb681ef2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
